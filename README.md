# MODA-MOdalities-for-Disability-Assistance
# Accessibility Assistant 

**A multimodal accessibility interface combining voice control and real-time sign language recognition** to support users with speech or hearing impairments. Built with a focus on inclusive design, the assistant bridges communication gaps using audio and visual modalities through an intuitive GUI.

---

## ğŸ”‘ Project Highlights
- Voice command recognition and TTS (Text-to-Speech)
- Real-time sign language gesture detection using webcam
- Accessible GUI with toggle buttons and keyboard shortcuts
- Output console for feedback visibility
- Modular design for extendibility

---

## ğŸ› ï¸ Technical Stack
- **Language**: Python 3.x  
- **Libraries**:
  - `speech_recognition`, `pyttsx3` â€“ Voice recognition and synthesis  
  - `cv2`, `mediapipe`, `numpy` â€“ Sign language gesture detection  
  - `tkinter`, `ttk` â€“ GUI interface  
  - `pynput` â€“ Global keyboard shortcut handling  
- **Architecture**: Modular, event-driven, multithreaded

---

## âœ¨ Features
- ğŸ”Š **Voice Mode**: Start/stop listening via GUI or F1 key  
- âœ‹ **Sign Mode**: Recognizes signs like Hello, Yes, No, OK, Help, etc.  
- ğŸ§  **Smart Feedback**: Text and audio-based response to commands  
- ğŸ–¥ï¸ **GUI Console**: Visual feedback log of interactions  

---

## ğŸ” Security & Privacy
- No external data transmission; all recognition is performed locally  
- No persistent audio/video recording â€” only live session data is used  
- Camera access is session-based and disabled when not in use  

---

## ğŸ¨ UI/UX Design
- Accessible fonts and contrast-friendly color palette  
- Logical grouping of functions for intuitive navigation  
- Real-time status indicators  
- Large buttons for ease of interaction  

---

## ğŸ“± Responsive Design
- Dynamic resizing using Tkinter layout managers  
- Scrollable console for small screens  
- Keyboard shortcuts (F1 for voice, F2 for sign) for quick access  

---

## ğŸš€ Future Scope
- ğŸ”¤ Broader sign language dataset for alphabet/word detection  
- ğŸŒ NLP-based task execution (email, calendar, browsing)  
- ğŸ“± Cross-platform mobile app with camera & mic access  
- ğŸ§© Plugin system for adding new modalities (eye tracking, Braille IO)  

---

## âš™ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/your-username/accessibility-assistant.git

# Navigate into the project folder
cd accessibility-assistant

# Install required packages
pip install -r requirements.txt

# Run the assistant
python code.py
```

---

## ğŸ“¬ Contact / Issues
For contributions, feature requests, or bug reports, please open an issue or reach out via GitHub.
## ğŸ¤ Contributing
Contributions are welcome! Please fork the repository and use a feature branch. Pull requests are warmly welcome.

**Let's build inclusive tech, one modality at a time.**
